import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score
import scipy.cluster.hierarchy as sch

from google.colab import files
uploaded = files.upload()

pd.set_option('display.max_columns', None)
sales = pd.read_csv('sales_data_sample.csv', encoding='ISO-8859-1')
print("Dataset Loaded Successfully\n")

print("Shape:", sales.shape)
print(sales.info())
print("\nMissing Values:\n", sales.isna().sum())

sales['TERRITORY'] = sales['TERRITORY'].fillna('Americas')
df = sales[['QUANTITYORDERED', 'PRICEEACH', 'SALES', 'ORDERDATE', 
            'PRODUCTLINE', 'COUNTRY', 'TERRITORY', 'DEALSIZE']]
df['ORDERDATE'] = pd.to_datetime(df['ORDERDATE'], format='%m/%d/%Y %H:%M', errors='coerce')

print("\n Columns after selection:")
print(df.head())

df = pd.concat([df, pd.get_dummies(df['PRODUCTLINE']).astype(int)], axis=1)
df = pd.concat([df, pd.get_dummies(df['TERRITORY']).astype(int)], axis=1)
df = pd.concat([df, pd.get_dummies(df['DEALSIZE']).astype(int)], axis=1)

X = df.drop(columns=['ORDERDATE', 'PRODUCTLINE', 'COUNTRY', 'TERRITORY', 'DEALSIZE'])
upper_limit = X['QUANTITYORDERED'].quantile(0.75) + 1.5 * (X['QUANTITYORDERED'].quantile(0.75) - X['QUANTITYORDERED'].quantile(0.25))
X = X[X['QUANTITYORDERED'] <= upper_limit]
X = X.reset_index(drop=True)

upper_limit_sales = X['SALES'].quantile(0.75) + 1.5 * (X['SALES'].quantile(0.75) - X['SALES'].quantile(0.25))
X = X[X['SALES'] <= upper_limit_sales]
X = X.reset_index(drop=True)

print("\n Data after removing outliers:", X.shape)

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X.iloc[:, :3])  # scale numerical columns
X_scaled = pd.DataFrame(X_scaled, columns=['QUANTITYORDERED', 'PRICEEACH', 'SALES'])
X_scaled = pd.concat([X_scaled, X.iloc[:, 3:].reset_index(drop=True)], axis=1)

print("\n Data normalized successfully")

wcss = []
max_k = 30

for i in range(1, max_k + 1):
    kmeans = KMeans(n_clusters=i, random_state=42, n_init='auto')
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(10, 5))
plt.plot(range(1, max_k + 1), wcss, marker='o')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('WCSS')
plt.grid()
plt.show()

optimal_k = 20  # as observed from the elbow plot
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init='auto')
cluster_labels_kmeans = kmeans.fit_predict(X_scaled)

silhouette_kmeans = silhouette_score(X_scaled, cluster_labels_kmeans)
print(f"\n K-Means Silhouette Score: {silhouette_kmeans:.4f}")


hierarchical_cluster_model = AgglomerativeClustering(n_clusters=optimal_k, linkage='ward')
X['Hierarchical_Cluster'] = hierarchical_cluster_model.fit_predict(X_scaled)

silhouette_avg = silhouette_score(X_scaled, X['Hierarchical_Cluster'])
print(f"Hierarchical Clustering Silhouette Score: {silhouette_avg:.4f}")

plt.figure(figsize=(10, 6))
linkage_matrix = sch.linkage(X_scaled, method='ward')
sch.dendrogram(linkage_matrix)
plt.title("Hierarchical Clustering Dendrogram")
plt.xlabel("Data Points")
plt.ylabel("Distance")
plt.show()
